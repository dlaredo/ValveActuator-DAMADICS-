{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from datetime import datetime\n",
    "import CMAPSAuxFunctions\n",
    "\n",
    "from data_handler_VALVE import ValveDataHandler\n",
    "from tunable_model import SequenceTunableModelRegression\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn import metrics\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input, Dropout, Reshape, Conv2D, Flatten, MaxPooling2D, LeakyReLU\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.callbacks import LearningRateScheduler, EarlyStopping\n",
    "from keras import backend as K\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Create Data Handler </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "features = ['id', 'timestamp', 'externalControllerOutput',\n",
    "            'pressureValveInlet', 'pressureValveOutlet', 'mediumTemperature',\n",
    "            'rodDisplacement', 'disturbedMediumFlow', 'selectedFault',\n",
    "            'faultType', 'faultIntensity']\n",
    "selected_indices = np.array([3,4,5,6,7,8])\n",
    "selected_features = list(features[i] for i in selected_indices-1)\n",
    "\n",
    "window_size = 30\n",
    "window_stride = 20\n",
    "\n",
    "# min = 2018-02-14 18:59:20\n",
    "# max = 2018-08-19 18:28:20\n",
    "time_start = \"2018-02-14 18:59:20\"\n",
    "time_end = \"2018-04-19 18:28:20\"\n",
    "\n",
    "# Either anomaly, classification or regression\n",
    "#problem = 'anomaly'\n",
    "problem = 'classification'\n",
    "#problem = 'regression'\n",
    "\n",
    "vHandler = ValveDataHandler(time_start, time_end, selected_features = selected_features,\n",
    "                            sequence_length = window_size, sequence_stride = window_stride,\n",
    "                            problem = problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['externalControllerOutput', 'pressureValveInlet', 'pressureValveOutlet', 'mediumTemperature', 'rodDisplacement', 'disturbedMediumFlow']\n"
     ]
    }
   ],
   "source": [
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Keras Model </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.set_printoptions(threshold=np.nan)\n",
    "\n",
    "K.clear_session()\n",
    "lambda_regularization = 0.20\n",
    "\n",
    "def create_ANN_model(input_shape, problem):\n",
    "    \n",
    "    #Create a sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    #Add the layers for the model\n",
    "    model.add(Dense(8, input_dim = input_shape, activation = 'relu'))\n",
    "    model.add(LeakyReLU(alpha = 0.001))\n",
    "    model.add(Dense(15, activation = 'relu'))\n",
    "    model.add(LeakyReLU(alpha = 0.001))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    \n",
    "#     if (problem == 'classification' or problem == 'anomaly'):\n",
    "#         model.add(Dense(1, activation = 'sigmoid', name = 'out'))\n",
    "#     elif (problem == 'regression'):\n",
    "#         model.add(Dense(1, activation = 'linear', name = 'out'))\n",
    "        \n",
    "    #model.add(Dense(1, activation = 'softmax', name = 'out'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Tunable Model </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default: Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
    "# Default: RMSprop(lr=0.001, rho=0.9, epsilon=1e-6)\n",
    "# Default: SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)\n",
    "\n",
    "def get_compiled_model(shape, problem):\n",
    "    \n",
    "    K.clear_session()\n",
    "    \n",
    "    if (problem == 'classification' or problem == 'anomaly'):\n",
    "        # Parameters for the model\n",
    "        learning_rate = 0.01\n",
    "        decay_rate = 0\n",
    "        \n",
    "        optimizer = SGD(lr = learning_rate, momentum=0.0, decay = decay_rate, nesterov=False)\n",
    "        loss_function = 'binary_crossentropy'\n",
    "        metrics = ['binary_accuracy']\n",
    "        \n",
    "    elif (problem == 'regression'):\n",
    "        # Parameters for the model\n",
    "        optimizer = Adam(lr = 0.1, beta_1 = 0.9, beta_2 = 0.999, epsilon = None, decay = 0.0, amsgrad = False)\n",
    "        loss_function = 'mean_squared_error'\n",
    "        metrics = ['mse']\n",
    "        \n",
    "    model = None\n",
    "    \n",
    "    # Create and compile the model\n",
    "    model = create_ANN_model(shape, problem)\n",
    "    model.compile(optimizer = optimizer, loss = loss_function, metrics = metrics)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = None\n",
    "num_features = len(selected_features)\n",
    "input_shape = num_features * window_size\n",
    "# scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "scaler = StandardScaler()\n",
    "\n",
    "model = get_compiled_model(input_shape, problem)\n",
    "tModel = SequenceTunableModelRegression('ANN_Model', model, lib_type = 'keras', data_handler = vHandler, data_scaler = scaler, batch_size = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Pulling Data from CSV </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vHandler._df = pd.read_csv('valve_dataset.csv', sep = ',')\n",
    "\n",
    "vHandler._df['status'] = vHandler._df['selectedFault'].apply(lambda valve: 0 if valve == 20 else 1)\n",
    "\n",
    "vHandler._X = vHandler._df[selected_features].values\n",
    "vHandler._y = vHandler._df['status'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Loading Data from MySQL Database </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vHandler.connect_to_db(\"remoteAdmin\",\"remoteAdmin\",\"169.236.181.40:3306\",\"damadics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from database\n",
    "#vHandler.extract_data_from_db()\n",
    "# vHandler.extract_data_from_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.00000e-01 8.76840e-01 6.50832e-01 2.14553e-01 1.59000e-03 1.00000e+00]\n",
      " [3.66043e-01 8.50576e-01 6.43717e-01 2.15373e-01 3.69939e-01 1.00000e+00]\n",
      " [7.32444e-01 8.49537e-01 6.47472e-01 2.14781e-01 7.32446e-01 2.22181e-01]\n",
      " ...\n",
      " [7.32444e-01 8.47251e-01 6.43362e-01 2.14299e-01 1.00000e+00 0.00000e+00]\n",
      " [2.57854e-01 8.49342e-01 6.43664e-01 2.15743e-01 1.00000e+00 3.34000e-04]\n",
      " [6.59356e-01 8.49701e-01 6.43186e-01 2.17503e-01 1.00000e+00 0.00000e+00]]\n",
      "[0 0 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(vHandler._X)\n",
    "print(vHandler._y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tModel.load_data(unroll = True, verbose = 0, cross_validation_ratio = 0.45, test_ratio = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vHandler.print_data(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Train Model and Test Tunable Model Functionalities </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tModel.epochs = 10\n",
    "# tModel.train_model(verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predicting the test set\n",
    "# tModel.predict_model(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "model = None\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim = input_shape, activation = 'elu'))\n",
    "model.add(LeakyReLU(alpha = 0.001))\n",
    "model.add(Dense(10, activation = 'elu'))\n",
    "model.add(LeakyReLU(alpha = 0.001))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "#opt = 'adam'\n",
    "#opt = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=1e-6, amsgrad=False)\n",
    "opt = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "callbacks = None\n",
    "#callbacks = [EarlyStopping(monitor='val_binary_accuracy', patience = 2)]\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = opt, metrics = ['binary_accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 50\n",
    "\n",
    "full_history = []\n",
    "\n",
    "history = model.fit(tModel._X_train, tModel._y_train, batch_size = batch_size,\n",
    "          validation_data = (tModel._X_crossVal, tModel._y_crossVal),\n",
    "          callbacks = callbacks,\n",
    "          epochs = epochs, shuffle = True)\n",
    "\n",
    "full_history.append(history)\n",
    "\n",
    "#model.fit(tModel._X_crossVal, tModel._y_crossVal, validation_data = (tModel._X_test, tModel._y_test), epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(tModel._X_crossVal)\n",
    "#print(np.ravel(predictions))\n",
    "print(np.ravel(np.round(predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.ravel(tModel._y_crossVal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "middle_value = 0.20\n",
    "\n",
    "new_predictions = None\n",
    "new_predictions = []\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    if (predictions[i] <= middle_value):\n",
    "        new_predictions.append(0.)\n",
    "    else:\n",
    "        new_predictions.append(1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.ravel(tModel._y_crossVal))\n",
    "print(np.ravel(new_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(tModel._X_test, tModel._y_test)\n",
    "print('''Loss of test set: {}\n",
    "Accuracy of test set: {}%'''\n",
    "      .format(scores[0], round(scores[1] * 100, 6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_correct = 0\n",
    "j = 0\n",
    "\n",
    "for i in predictions:\n",
    "    if tModel._y_crossVal[j] == np.round(i):\n",
    "        num_correct += 1\n",
    "    j += 1\n",
    "\n",
    "print(\"Number of correct predictions: {} out of {}\".format(num_correct, len(tModel._y_crossVal)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
