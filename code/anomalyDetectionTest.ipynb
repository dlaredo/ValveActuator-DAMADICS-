{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Initialization\n",
    "\n",
    "Test notebook for the damadics benchmark. Approach using anomaly detection techniques. \n",
    "\n",
    "First we import the necessary packages and create the global variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import logging\n",
    "import random\n",
    "import plottingTools\n",
    "import sys\n",
    "import datetime\n",
    "import graphviz \n",
    "\n",
    "sys.path.append('/Users/davidlaredorazo/Documents/University_of_California/Research/Projects')\n",
    "\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns; sns.set(font_scale=1.2)\n",
    "\n",
    "from ann_framework.data_handlers.data_handler_DAMADICS import DamadicsDataHandler\n",
    "\n",
    "#Import the tunable model classes\n",
    "from ann_framework.tunable_model.tunable_model import SequenceTunableModelClassification\n",
    "\n",
    "\n",
    "#from IPython.display import display, HTML\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup some options for the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 0 #Change this to make it really random, 0 for testing purposes\n",
    "random.seed(random_seed)\n",
    "\n",
    "y_trains = {'DummyClf':None, 'EllipticEnvelope':list(), 'MLP':None}\n",
    "y_tests = {'DummyClf':None, 'EllipticEnvelope':list(), 'MLP':None}\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "nsamples = 1000\n",
    "scoringMetrics = ['precision_macro', 'recall_macro', 'f1_macro']\n",
    "cv_folds = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create data hanlder and load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to mysql+mysqldb://readOnly:_readOnly2019@169.236.181.40/damadics successfull\n"
     ]
    }
   ],
   "source": [
    "features = ['externalControllerOutput', 'undisturbedMediumFlow', 'pressureValveInlet', \n",
    "            'pressureValveOutlet', 'mediumTemperature', 'rodDisplacement', 'disturbedMediumFlow', \n",
    "           'selectedFault', 'faultType', 'faultIntensity']\n",
    "\n",
    "selected_indices = np.array([1,3,4,5,6,7])\n",
    "selected_features = list(features[i] for i in selected_indices-1)\n",
    "\n",
    "#Does not work for sequence sizes larger than 1 given the way I'm generating the test data. \n",
    "#Need to properly define what the test data is going to be like.\n",
    "window_size = 1\n",
    "window_stride = 1\n",
    "\n",
    "dHandlder_valve = DamadicsDataHandler(selected_features, window_size, window_stride, \n",
    "                                      binary_classes=True)\n",
    "dHandlder_valve.connect_to_db('readOnly', '_readOnly2019', '169.236.181.40', 'damadics')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform classification using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for the first time\n",
      "Reloading data due to parameter change\n",
      "Loading data for DAMADICS with window_size of 1, stride of 1. Cros-Validation ratio 0\n",
      "Loading data from memory\n",
      "Data Splitting: 0:00:00.000614\n",
      "Printing shapes\n",
      "\n",
      "Training data (X, y)\n",
      "(205737, 6)\n",
      "(205737, 1)\n",
      "Testing data (X, y)\n",
      "(250, 6)\n",
      "(250, 1)\n",
      "Printing first 5 elements\n",
      "\n",
      "Training data (X, y)\n",
      "[[3.66043e-01 8.49866e-01 6.49667e-01 2.13222e-01 9.99784e-01 0.00000e+00]\n",
      " [6.59356e-01 8.49437e-01 6.45173e-01 2.16581e-01 9.99018e-01 1.06700e-03]\n",
      " [6.59356e-01 8.50019e-01 6.50535e-01 2.12273e-01 9.98577e-01 0.00000e+00]\n",
      " [4.84302e-01 8.51305e-01 6.47092e-01 2.11460e-01 4.59894e-01 8.49068e-01]\n",
      " [7.32444e-01 8.49901e-01 6.48759e-01 2.12886e-01 1.00000e+00 9.19000e-04]]\n",
      "[[-1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]]\n",
      "Testing data (X, y)\n",
      "[[0.366043 0.84907  0.652659 0.214973 1.       0.001396]\n",
      " [0.366043 0.846921 0.642378 0.215928 0.999881 0.      ]\n",
      " [0.732444 0.849215 0.644677 0.215841 1.       0.      ]\n",
      " [0.257854 0.850184 0.646255 0.216564 0.484861 0.748222]\n",
      " [0.732444 0.84863  0.651341 0.211237 0.999354 0.      ]]\n",
      "[[-1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]]\n"
     ]
    }
   ],
   "source": [
    "start_date = datetime.datetime(2018, 2, 14, 18, 59, 20)\n",
    "time_delta = datetime.timedelta(days=0, seconds=0, microseconds=0, milliseconds=0, minutes=1, hours=0, weeks=0)\n",
    "n = 250000\n",
    "end_date = start_date + n*time_delta #get the first n instances\n",
    "\n",
    "## Binary classification using decision tree (must get 95+% for this simple task)\n",
    "\n",
    "tree_clf = tree.DecisionTreeClassifier()\n",
    "\n",
    "tModel = SequenceTunableModelClassification('Damadics_Tree_SK', tree_clf, lib_type='scikit', data_handler=dHandlder_valve)\n",
    "tModel.load_data(unroll=True, verbose=1, test_ratio=0.20, \n",
    "                 start_date=start_date, end_date=end_date)\n",
    "tModel.print_data(print_top=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tModel.train_model(verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On test set\n",
      "0.612\n",
      "On train set\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "tModel.predict_model()\n",
    "tModel.evaluate_model()\n",
    "\n",
    "predicted = tModel.y_predicted\n",
    "test = tModel.y_test\n",
    "test = np.ravel(test)\n",
    "\n",
    "print(\"On test set\")\n",
    "print(accuracy_score(test, predicted))\n",
    "\n",
    "clf = tModel.model\n",
    "y_train_pred = clf.predict(tModel.X_train)\n",
    "\n",
    "train = tModel.y_train\n",
    "train = np.ravel(train)\n",
    "\n",
    "print(\"On train set\")\n",
    "print(accuracy_score(tModel.y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['externalControllerOutput', 'pressureValveInlet', 'pressureValveOutlet', 'mediumTemperature', 'rodDisplacement', 'disturbedMediumFlow']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-3143d6869c66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'decision_tree_damadics'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda/envs/tensorflow/lib/python3.6/site-packages/graphviz/files.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, filename, directory, view, cleanup, format, renderer, formatter)\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0mformat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mrendered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcleanup\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tensorflow/lib/python3.6/site-packages/graphviz/backend.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(engine, format, filepath, renderer, formatter, quiet)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \"\"\"\n\u001b[1;32m    182\u001b[0m     \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrendered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m     \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapture_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquiet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrendered\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tensorflow/lib/python3.6/site-packages/graphviz/backend.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(cmd, input, capture_output, check, quiet, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mquiet\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tensorflow/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m                 \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communication_started\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tensorflow/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m_communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   1532\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutExpired\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1534\u001b[0;31m                     \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1535\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tensorflow/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "feature_names = features[:1] + features[2:7]\n",
    "print(feature_names)\n",
    "\n",
    "dot_data = tree.export_graphviz(clf, out_file=None,\n",
    "                                feature_names=feature_names,  \n",
    "                                class_names=[\"normal\", \"fault\"],  \n",
    "                                filled=True, rounded=True, special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)  \n",
    "#graph \n",
    "\n",
    "graph.render('decision_tree_damadics', view=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate some plots\n",
    "\n",
    "We now generate some useful plots to gain some insight on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dHandlder_valve._X_train\n",
    "n = X.shape[0]\n",
    "\n",
    "n=6\n",
    "plt.plot(np.arange(0,n), X[:6,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jplot_vars = ['externalControllerOutput', 'disturbedMediumFlow', 'pressureValveInlet', 'pressureValveOutlet', \n",
    "              'mediumTemperature', 'rodDisplacement']\n",
    "\n",
    "df_sp = df[['pressureValveInlet', 'pressureValveOutlet', 'selectedFault']]\n",
    "plottingTools.scatterplot_fault(df_sp, \"Normal vs Faulty observations\", nsamples = 200)\n",
    "\n",
    "df_jp = df\n",
    "df_jp.loc[df_jp['selectedFault'] != 20, 'selectedFault'] = 1\n",
    "df_jp.loc[df_jp['selectedFault'] == 20, 'selectedFault'] = 0\n",
    "\n",
    "plottingTools.jp_plotData(df_jp, \"Joint plot\", hue='selectedFault', saveToFile='damadicsPairPlot.png', vars = jplot_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Binary classification using decision tree (must get 95+% for this simple task)\n",
    "\n",
    "#reformat labels using sklearn's decision tree format\n",
    "y_train_binary = [-1 if int(y_train[0]) == 20 else 1 for y_train in dHandlder_valve._y_train]\n",
    "\n",
    "tree_clf = tree.DecisionTreeClassifier(max_depth=6, min_samples_leaf=5)\n",
    "\n",
    "tModel = SequenceTunableModelClassification('Damadics_Tree_SK', tree_clf, lib_type='scikit', data_handler=dHandlder_valve)\n",
    "tModel\n",
    "\n",
    "tree_clf.fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = tree.export_graphviz(clf, out_file=None,\n",
    "                                feature_names=iris.feature_names,  \n",
    "                                class_names=iris.target_names,  \n",
    "                                filled=True, rounded=True, special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot encoding\n",
    "#cat = np.arange(1,5)\n",
    "#encoder = OneHotEncoder(categories=[cat])\n",
    "#encoder = OneHotEncoder(categories=[[20]])\n",
    "#output_one_hot_matrix = encoder.fit_transform(dHandlder_valve._y.reshape(-1, 1)).toarray()\n",
    "#print(encoder.categories_)\n",
    "#print(self._y[:5])\n",
    "#print(output_one_hot_matrix[:5, :])\n",
    "#output_one_hot_matrix = self.one_hot_encode(self._df.shape[0])\n",
    "#output_one_hot_matrix = encoder.fit_transform(self._y.reshape(-1, 1)).toarray()\n",
    "#self._y = encoder.fit_transform(self._y.reshape(-1, 1)).toarray()\n",
    "#dHandlder_valve.print_data(print_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_elliptic = y_train\n",
    "y_test_elliptic = y_test\n",
    "y_train_elliptic[y_train_elliptic == 0] = -1\n",
    "y_test_elliptic[y_test_elliptic == 0] = -1\n",
    "y_trains['EllipticEnvelope'] = y_train_elliptic\n",
    "y_tests['EllipticEnvelope'] = y_test_elliptic\n",
    "\n",
    "logger.info('Performing cross validations')\n",
    "\n",
    "#print(X_train.shape)\n",
    "#print(y_train.shape)\n",
    "\n",
    "for classifierKey in classifiers:\n",
    "    \n",
    "    print('\\nResults for {} classifier'.format(classifierKey))\n",
    "    \n",
    "    clf = classifiers[classifierKey]\n",
    "    \n",
    "    if y_trains[classifierKey] is not None:\n",
    "        y_train = y_trains[classifierKey]\n",
    "        \n",
    "    cv_scores = cross_validate(clf, X_train, y_train[:,0], scoring=scoringMetrics, cv=cv_folds, return_train_score=True)\n",
    "        \n",
    "    print('{}-fold cross validation'.format(cv_folds))\n",
    "        \n",
    "    for key in cv_scores:\n",
    "        print(\"For metric %s Accuracy: %0.5f (+/- %0.5f)\" % (key, cv_scores[key].mean(), cv_scores[key].std() * 2))\n",
    "    #print('Total sample size {}, Train Size {}, Test Size {}'.format(X_raw.shape[0], X_train.shape[0], X_test.shape[0]))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
